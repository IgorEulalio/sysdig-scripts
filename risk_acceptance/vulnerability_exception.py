import csv
import requests
import sys
import os
import argparse
import datetime
import uuid
import time
import logging
import urllib3

#disable ssl warnings
urllib3.disable_warnings()

# Setup logger
LOG = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s.%(msecs)03d %(levelname)s - %(funcName)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logging.getLogger("urllib3").setLevel(logging.CRITICAL)

def retrieve_set_sysdig_params():
    parser = argparse.ArgumentParser()
    parser.add_argument("--base-url", dest='sysdig_base_url', type=str,
                        help="Base url of sysdig. ex: us2.app.sysdig.com")
    parser.add_argument("--api-token", dest='sysdig_api_token',
                        type=str, help="Sysdig API Token")
    parser.add_argument("--acceptance-files-directory", dest='acceptance_files_directory',
                        type=str, help="Full path to directory containing csv files for acceptance")
    parser.add_argument("--ssl-verification", dest='ssl_verification',
                        type=str, help="enabled or disabled for values. Default is disabled.")
    return parser.parse_args()


def retrieve_sysdig_header_url(args):
    auth_token = args.sysdig_api_token
    auth_header = {'Authorization': 'Bearer ' + auth_token}
    base_url = args.sysdig_base_url.replace("https://", "")
    url = f'https://{base_url}/api/scanning/riskmanager/v2/definitions'
    return auth_header, url


def validate_date_format(date_text):
    try:
        datetime.date.fromisoformat(date_text)
    except ValueError:
        raise ValueError("Incorrect data format for ",
                         date_text, " should be YYYY-MM-DD")


def retrieve_existing_exceptions(auth_header, url, ssl_verification):
    existing_risk_exceptions = []
    existing_entity_exceptions = []
    existing_entity_exceptions_dict = {}

    try:
        response = requests.get(url, headers=auth_header, params={
                                'limit': 100}, verify=ssl_verification)
        response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        LOG.critical(" ERROR ".center(80, "-"))
        LOG.critical(e)
    except requests.exceptions.RequestException as e:
        LOG.critical(e)
    existing_risk_exceptions.append((response.json()['data']))

    while (response.json()['page']['next'] != ""):
        try:
            response = requests.get(url, headers=auth_header, params={
                'cursor': response.json()['page']['next'], 'limit': 100}, verify=ssl_verification)
            response.raise_for_status()
        except requests.exceptions.HTTPError as e:
            LOG.critical(" ERROR ".center(80, "-"))
            LOG.critical(e)
        except requests.exceptions.RequestException as e:
            LOG.critical(e)
        existing_risk_exceptions.append(response.json()['data'])

    for existing_risk_exception in existing_risk_exceptions:
        for risk_exception in existing_risk_exception:
            existing_entity_exceptions_dict = {
                "entityValue": risk_exception['entityValue'], "context": risk_exception['context']}
            existing_entity_exceptions.append(existing_entity_exceptions_dict)

    return existing_risk_exceptions, existing_entity_exceptions


def append_new_exception(entity_dups, risks, entity, expiration_date, reason, description, context_dict):
    # print("Adding new exception for :", entity)
    entity_dups_dict = {"entityValue": entity, "context": context_dict}
    entity_dups.append(entity_dups_dict)
    # print("updating entity dups: ", entity_dups)
    if "contextValue" in context_dict.keys():
        if context_dict['contextType'] == "imageName":
            risk_exception = {"entityType": "vulnerability", "entityValue": entity, "expirationDate": expiration_date, "context": [
                context_dict], "reason": reason, "description": description}
    else:
        risk_exception = {"entityType": "vulnerability", "entityValue": entity, "expirationDate": expiration_date, "context": [
        ], "reason": reason, "description": description}
    risks.append(risk_exception)
    return entity_dups, risks


def determine_exception_changes(auth_header, url, ssl_verification, existing_risk_exceptions, entity, expiration_date, reason, description, contextType, context_dict):
    change_detected = False
    description_url = ""
    for existing_risk_exception in existing_risk_exceptions:
        for risk_exception in existing_risk_exception:
            apply_update = False
            new_expiration = risk_exception['expirationDate']
            new_reason = risk_exception['reason']
            appended_note = risk_exception['description']
            if entity == risk_exception['entityValue']:
                if expiration_date != risk_exception['expirationDate']:
                    new_expiration = expiration_date
                    change_detected = True
                if reason != risk_exception['reason']:
                    new_reason = reason
                    change_detected = True
                if description != risk_exception['description']:
                    # print("Appending note for entity: ",
                    #       risk_exception['entityValue'])
                    appended_note = risk_exception['description'] + \
                        description
                    change_detected = True
                if change_detected:
                    if contextType == "imageName":
                        if context_dict['contextValue'] == risk_exception['context'][0]['contextValue']:
                            updated_risk_exception = {"entityType": "vulnerability", "entityValue": risk_exception['entityValue'], "expirationDate": new_expiration, "context": [
                            context_dict], "reason": new_reason, "description": appended_note}
                            description_url = url + "/" + \
                                risk_exception['riskAcceptanceDefinitionID']
                            apply_update = True
                    elif contextType == "global":
                        updated_risk_exception = {"entityType": "vulnerability", "entityValue": risk_exception['entityValue'], "expirationDate": new_expiration, "context": [
                        ], "reason": new_reason, "description": appended_note}
                        description_url = url + "/" + \
                            risk_exception['riskAcceptanceDefinitionID']
                        apply_update = True
                    if (apply_update):
                        try:
                            # print("Updating entity##################: ", entity, updated_risk_exception, description_url, risk_exception, context_dict)
                            response = requests.put(
                                description_url, json=updated_risk_exception, headers=auth_header, verify=ssl_verification)
                            response.raise_for_status()
                        except requests.exceptions.HTTPError as e:
                            LOG.critical(" ERROR ".center(80, "-"), "entity:", entity)
                            LOG.critical("Failed updating entity", e)
                        except requests.exceptions.RequestException as e:
                            LOG.critical(" ERROR ".center(80, "-"), "entity:", entity)
                            LOG.critical(e, "Failed updating entity")


def process_exceptions(auth_header, url, ssl_verification, directory_path, existing_risk_exceptions, existing_entity_exceptions):
    new_risks_added = []
    for csv_data in os.listdir(directory_path):
        try:
            filename_with_path = f'{directory_path}/' + csv_data
            if os.path.isfile(filename_with_path):
                with open(filename_with_path) as csv_file:
                    csv_reader = csv.reader(csv_file, delimiter=',')
                    line_count = 0
                    risks = []
                    entity_dups = []
                    for row in csv_reader:
                        context_dict = {}
                        entity = row[0]
                        expiration_date = row[1]
                        reason = row[2]
                        description = row[3]
                        contextType = row[4]
                        if contextType == "imageName":
                            contextValue = row[5]
                            context_dict = {
                                "contextType": contextType, "contextValue": contextValue}
                        if line_count == 0:
                            # print(f'Column names are {", ".join(row)}')
                            line_count += 1
                        else:
                            # validate date before going any further
                            validate_date_format(expiration_date)
                            exists = False
                            for entry in existing_entity_exceptions:
                                if entry['entityValue'] == entity:
                                    if not context_dict:
                                        exists = True
                                    elif entry['context'] and context_dict:
                                        if entry['context'][0]['contextType'] == context_dict['contextType'] and entry['context'][0]['contextValue'] == context_dict['contextValue']:
                                            LOG.debug("entry already exists " + str(entry['entityValue']))
                                            exists = True
                                    
                            if exists == False:
                                # print("new entry", entity, context_dict)
                                entity_dups, risks = append_new_exception(
                                    entity_dups, risks, entity, expiration_date, reason, description, context_dict)
                                existing_entity_exceptions_dict = {
                                    "entityValue": entity, "context": [context_dict]}
                                existing_entity_exceptions.append(existing_entity_exceptions_dict)
                            else:
                                # if contextType == "global":
                                determine_exception_changes(
                                    auth_header, url, ssl_verification, existing_risk_exceptions, entity, expiration_date, reason, description, contextType, context_dict)

                            line_count += 1
                LOG.info(f'Processed {line_count} lines.')
        except OSError as e:
            LOG.critical("FILE NOT FOUND".center(80, "-"))
            LOG.critical(e)
            sys.exit()

        # risk_exceptions = {"riskAcceptanceDefinitions": risks}

        if (len(risks) > 0):
            counter = 0 
            try:
                LOG.info("Adding new risk exceptions...")
                for risk_exception in risks:
                    response, new_risks_added = post_request(
                        url, risk_exception, auth_header, ssl_verification, new_risks_added)
                LOG.info("added " + str(len(new_risks_added)) + " new exceptions")
                    # counter +=1
                    # if counter == 60:
                    #         print("Sleep 5 secs...")
                    #         time.sleep(5)
                    # response.raise_for_status()
                # print(risk_exceptions)
                # response = requests.post(
                #     url, json=risk_exceptions, headers=auth_header, verify=ssl_verification)
                # response.raise_for_status()
            except requests.exceptions.HTTPError as e:
                LOG.critical(" ERROR ".center(80, "-"))
                LOG.critical("Failed adding new risk acceptance", e)
                LOG.critical(response.text)
            except requests.exceptions.RequestException as e:
                LOG.critical(" ERROR ".center(80, "-"))
                LOG.critical(e, "Failed adding new risk acceptance")
        LOG.info(f"Done processing file: {filename_with_path}")

def post_request(url, risk, auth_header, ssl_verification, new_risks_added):
    try:
        num_of_429 = 0
        num_of_504 = 0
        num_of_503 = 0
        response = None
        risk_array = [risk]
        risk_exception = {"riskAcceptanceDefinitions": risk_array}

        while True:
            LOG.debug(f"Sending http request to: {url}")

            LOG.debug(f"Risk exception: {risk_array[0]['entityValue']}")
            new_risks_added.append(risk_array[0]['entityValue'])

            response = requests.post(
                url, json=risk_exception, headers=auth_header, verify=ssl_verification)

            LOG.debug(f"response status: {response.status_code}")
            if response.status_code == 200 or response.status_code == 201:
                #LOG.debug(f"Response data: {response_data}")
                break

            elif response.status_code in [ 429, 504 , 503]:

                if response.status_code == 429:
                    message = "API throttling"
                    num_of_429 += 1
                elif response.status_code == 504:
                    message = "Gateway Timeout"
                    num_of_504 += 1
                elif response.status_code == 503:
                    message = "Service Unavailable"
                    num_of_503 += 1

                LOG.debug(f"Response data: {response}")
                LOG.debug(f"Sleeping 60 seconds due to {message}...")

                for interval in range(1,60):
                   print(f"Sleeping {60-interval} seconds due to {message}...", end="\r")
                   time.sleep(1)

                # Extra space to clear earlier message
                print( "Retrying request...                                    ", end="\r")

                LOG.debug(f"Retrying request...")

            else:
                raise Exception(
                    f"Unexpected HTTP response status: {response.status_code}"
                )

        return response, new_risks_added

    except Exception as e:
        LOG.critical(e)
        LOG.critical(f"Error while requesting url: {url}")
        raise SystemExit(-1)


def split_csv(directory_path, max_rows):
    # Generate a unique ID
    unique_id = uuid.uuid4()
    # Convert the UUID to a string
    unique_id_str = str(unique_id)
    tmp_directory = "tmp-" + unique_id_str
    # Create the directory
    os.mkdir(f'{directory_path}/{tmp_directory}')
    for csv_data in os.listdir(directory_path):
        filename_with_path = f'{directory_path}/' + csv_data
        if os.path.isfile(filename_with_path):
            with open(filename_with_path, 'r') as file:
                reader = csv.reader(file)
                header = next(reader)  # Assuming the first row is the header

                file_number = 1
                row_count = 0
                output_file = f"{directory_path}/{tmp_directory}/output_{file_number}.csv"
                writer = csv.writer(open(output_file, 'w', newline=''))
                writer.writerow(header)

                for row in reader:
                    writer.writerow(row)
                    row_count += 1

                    if row_count == max_rows:
                        file_number += 1
                        row_count = 0
                        output_file = f"{directory_path}/{tmp_directory}/output_{file_number}.csv"
                        writer = csv.writer(open(output_file, 'w', newline=''))
                        writer.writerow(header)
    return tmp_directory

def main():
    args = retrieve_set_sysdig_params()
    auth_header, url = retrieve_sysdig_header_url(args)
    ssl_verification = False
    if (args.ssl_verification == "enabled"):
        ssl_verification = True
    LOG.info("Split csv files...")
    tmp_directory = split_csv(args.acceptance_files_directory, 100)
    work_directory = args.acceptance_files_directory + "/" + tmp_directory
    LOG.debug(work_directory)
    LOG.info("Retrieve existing exceptions...")
    existing_risk_exceptions, existing_entity_exceptions = retrieve_existing_exceptions(
        auth_header, url, ssl_verification)
    LOG.info("Process exceptions...")
    process_exceptions(
        auth_header, url, ssl_verification, work_directory, existing_risk_exceptions, existing_entity_exceptions)


if __name__ == "__main__":
    main()